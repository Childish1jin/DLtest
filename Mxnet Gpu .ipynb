{"cells":[{"metadata":{},"cell_type":"markdown","source":"# 卷积神经网络（LeNet）"},{"metadata":{"trusted":true},"cell_type":"code","source":"\nimport mxnet as mx\nfrom mxnet import autograd, gluon, init, nd\nfrom mxnet.gluon import loss as gloss, nn,data as gdata\n\nimport time\n\nnet = nn.Sequential()\nnet.add(nn.Conv2D(channels=6, kernel_size=5, activation='sigmoid'),\n        nn.MaxPool2D(pool_size=2, strides=2),\n        nn.Conv2D(channels=16, kernel_size=5, activation='sigmoid'),\n        nn.MaxPool2D(pool_size=2, strides=2),\n        # Dense会默认将(批量大小, 通道, 高, 宽)形状的输入转换成\n        # (批量大小, 通道 * 高 * 宽)形状的输入\n        nn.Dense(120, activation='sigmoid'),\n        nn.Dense(84, activation='sigmoid'),\n        nn.Dense(10))","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = nd.random.uniform(shape=(1, 1, 28, 28))\nnet.initialize()\nfor layer in net:\n    X = layer(X)\n    print(layer.name, 'output shape:\\t', X.shape)","execution_count":2,"outputs":[{"output_type":"stream","text":"conv0 output shape:\t (1, 6, 24, 24)\npool0 output shape:\t (1, 6, 12, 12)\nconv1 output shape:\t (1, 16, 8, 8)\npool1 output shape:\t (1, 16, 4, 4)\ndense0 output shape:\t (1, 120)\ndense1 output shape:\t (1, 84)\ndense2 output shape:\t (1, 10)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## 获取数据和训练模型\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"import os\nimport sys","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\ndef load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n    \"\"\"Download the fashion mnist dataset and then load into memory.\"\"\"\n    root = os.path.expanduser(root)\n    transformer = []\n    if resize:\n        transformer += [gdata.vision.transforms.Resize(resize)]\n    transformer += [gdata.vision.transforms.ToTensor()]\n    transformer = gdata.vision.transforms.Compose(transformer)\n\n    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n    num_workers = 0 if sys.platform.startswith('win32') else 4\n\n    train_iter = gdata.DataLoader(mnist_train.transform_first(transformer),\n                                  batch_size, shuffle=True,\n                                  num_workers=num_workers)\n    test_iter = gdata.DataLoader(mnist_test.transform_first(transformer),\n                                 batch_size, shuffle=False,\n                                 num_workers=num_workers)\n    return train_iter, test_iter\n","execution_count":4,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 256\ntrain_iter, test_iter = load_data_fashion_mnist(batch_size=batch_size)","execution_count":5,"outputs":[{"output_type":"stream","text":"Downloading /tmp/.mxnet/datasets/fashion-mnist/train-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-images-idx3-ubyte.gz...\nDownloading /tmp/.mxnet/datasets/fashion-mnist/train-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/train-labels-idx1-ubyte.gz...\nDownloading /tmp/.mxnet/datasets/fashion-mnist/t10k-images-idx3-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-images-idx3-ubyte.gz...\nDownloading /tmp/.mxnet/datasets/fashion-mnist/t10k-labels-idx1-ubyte.gz from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/fashion-mnist/t10k-labels-idx1-ubyte.gz...\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def try_gpu():  # 本函数已保存在d2lzh包中方便以后使用\n    try:\n        ctx = mx.gpu()\n        _ = nd.zeros((1,), ctx=ctx)\n    except mx.base.MXNetError:\n        ctx = mx.cpu()\n    return ctx\n\nctx = try_gpu()\nctx","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"gpu(0)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 本函数已保存在d2lzh包中方便以后使用。该函数将被逐步改进：它的完整实现将在“图像增广”一节中\n# 描述\ndef evaluate_accuracy(data_iter, net, ctx):\n    acc_sum, n = nd.array([0], ctx=ctx), 0\n    for X, y in data_iter:\n        # 如果ctx代表GPU及相应的显存，将数据复制到显存上\n        X, y = X.as_in_context(ctx), y.as_in_context(ctx).astype('float32')\n        acc_sum += (net(X).argmax(axis=1) == y).sum()\n        n += y.size\n    return acc_sum.asscalar() / n","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 本函数已保存在d2lzh包中方便以后使用\ndef train_ch5(net, train_iter, test_iter, batch_size, trainer, ctx,\n              num_epochs):\n    print('training on', ctx)\n    loss = gloss.SoftmaxCrossEntropyLoss()\n    for epoch in range(num_epochs):\n        train_l_sum, train_acc_sum, n, start = 0.0, 0.0, 0, time.time()\n        for X, y in train_iter:\n            X, y = X.as_in_context(ctx), y.as_in_context(ctx)\n            with autograd.record():\n                y_hat = net(X)\n                l = loss(y_hat, y).sum()\n            l.backward()\n            trainer.step(batch_size)\n            y = y.astype('float32')\n            train_l_sum += l.asscalar()\n            train_acc_sum += (y_hat.argmax(axis=1) == y).sum().asscalar()\n            n += y.size\n        test_acc = evaluate_accuracy(test_iter, net, ctx)\n        print('epoch %d, loss %.4f, train acc %.3f, test acc %.3f, '\n              'time %.1f sec'\n              % (epoch + 1, train_l_sum / n, train_acc_sum / n, test_acc,\n                 time.time() - start))","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr, num_epochs = 0.9, 5\nnet.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\ntrain_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)","execution_count":9,"outputs":[{"output_type":"stream","text":"training on gpu(0)\nepoch 1, loss 2.3199, train acc 0.102, test acc 0.100, time 7.7 sec\nepoch 2, loss 1.9980, train acc 0.231, test acc 0.559, time 7.9 sec\nepoch 3, loss 0.9816, train acc 0.613, test acc 0.705, time 8.3 sec\nepoch 4, loss 0.7686, train acc 0.701, test acc 0.737, time 7.9 sec\nepoch 5, loss 0.6717, train acc 0.734, test acc 0.750, time 8.0 sec\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# AlexNet"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mxnet import gluon, init, nd\nfrom mxnet.gluon import data as gdata, nn\nimport os\nimport sys\n\nnet = nn.Sequential()\n# 使用较大的11 x 11窗口来捕获物体。同时使用步幅4来较大幅度减小输出高和宽。这里使用的输出通\n# 道数比LeNet中的也要大很多\nnet.add(nn.Conv2D(96, kernel_size=11, strides=4, activation='relu'),\n        nn.MaxPool2D(pool_size=3, strides=2),\n        # 减小卷积窗口，使用填充为2来使得输入与输出的高和宽一致，且增大输出通道数\n        nn.Conv2D(256, kernel_size=5, padding=2, activation='relu'),\n        nn.MaxPool2D(pool_size=3, strides=2),\n        # 连续3个卷积层，且使用更小的卷积窗口。除了最后的卷积层外，进一步增大了输出通道数。\n        # 前两个卷积层后不使用池化层来减小输入的高和宽\n        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n        nn.Conv2D(384, kernel_size=3, padding=1, activation='relu'),\n        nn.Conv2D(256, kernel_size=3, padding=1, activation='relu'),\n        nn.MaxPool2D(pool_size=3, strides=2),\n        # 这里全连接层的输出个数比LeNet中的大数倍。使用丢弃层来缓解过拟合\n        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n        nn.Dense(4096, activation=\"relu\"), nn.Dropout(0.5),\n        # 输出层。由于这里使用Fashion-MNIST，所以用类别数为10，而非论文中的1000\n        nn.Dense(10))","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = nd.random.uniform(shape=(1, 1, 224, 224))\nnet.initialize()\nfor layer in net:\n    X = layer(X)\n    print(layer.name, 'output shape:\\t', X.shape)","execution_count":11,"outputs":[{"output_type":"stream","text":"conv2 output shape:\t (1, 96, 54, 54)\npool2 output shape:\t (1, 96, 26, 26)\nconv3 output shape:\t (1, 256, 26, 26)\npool3 output shape:\t (1, 256, 12, 12)\nconv4 output shape:\t (1, 384, 12, 12)\nconv5 output shape:\t (1, 384, 12, 12)\nconv6 output shape:\t (1, 256, 12, 12)\npool4 output shape:\t (1, 256, 5, 5)\ndense3 output shape:\t (1, 4096)\ndropout0 output shape:\t (1, 4096)\ndense4 output shape:\t (1, 4096)\ndropout1 output shape:\t (1, 4096)\ndense5 output shape:\t (1, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 本函数已保存在d2lzh包中方便以后使用\ndef load_data_fashion_mnist(batch_size, resize=None, root=os.path.join(\n        '~', '.mxnet', 'datasets', 'fashion-mnist')):\n    root = os.path.expanduser(root)  # 展开用户路径'~'\n    transformer = []\n    if resize:\n        transformer += [gdata.vision.transforms.Resize(resize)]\n    transformer += [gdata.vision.transforms.ToTensor()]\n    transformer = gdata.vision.transforms.Compose(transformer)\n    mnist_train = gdata.vision.FashionMNIST(root=root, train=True)\n    mnist_test = gdata.vision.FashionMNIST(root=root, train=False)\n    num_workers = 0 if sys.platform.startswith('win32') else 4\n    train_iter = gdata.DataLoader(\n        mnist_train.transform_first(transformer), batch_size, shuffle=True,\n        num_workers=num_workers)\n    test_iter = gdata.DataLoader(\n        mnist_test.transform_first(transformer), batch_size, shuffle=False,\n        num_workers=num_workers)\n    return train_iter, test_iter\n\nbatch_size = 128\n# 如出现“out of memory”的报错信息，可减小batch_size或resize\ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr, num_epochs, ctx = 0.01, 5, try_gpu()\nnet.initialize(force_reinit=True, ctx=ctx, init=init.Xavier())\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\ntrain_ch5(net, train_iter, test_iter, batch_size, trainer, ctx, num_epochs)","execution_count":13,"outputs":[{"output_type":"stream","text":"training on gpu(0)\nepoch 1, loss 1.3274, train acc 0.512, test acc 0.757, time 42.2 sec\nepoch 2, loss 0.6572, train acc 0.755, test acc 0.814, time 39.9 sec\nepoch 3, loss 0.5376, train acc 0.800, test acc 0.833, time 39.8 sec\nepoch 4, loss 0.4735, train acc 0.825, test acc 0.853, time 39.7 sec\nepoch 5, loss 0.4312, train acc 0.842, test acc 0.865, time 39.8 sec\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# VGG"},{"metadata":{"trusted":true},"cell_type":"code","source":"from mxnet import gluon, init, nd\nfrom mxnet.gluon import nn\n\ndef vgg_block(num_convs, num_channels):\n    blk = nn.Sequential()\n    for _ in range(num_convs):\n        blk.add(nn.Conv2D(num_channels, kernel_size=3,\n                          padding=1, activation='relu'))\n    blk.add(nn.MaxPool2D(pool_size=2, strides=2))\n    return blk","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"conv_arch = ((1, 64), (1, 128), (2, 256), (2, 512), (2, 512))","execution_count":15,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def vgg(conv_arch):\n    net = nn.Sequential()\n    # 卷积层部分\n    for (num_convs, num_channels) in conv_arch:\n        net.add(vgg_block(num_convs, num_channels))\n    # 全连接层部分\n    net.add(nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n            nn.Dense(4096, activation='relu'), nn.Dropout(0.5),\n            nn.Dense(10))\n    return net\n\nnet = vgg(conv_arch)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.initialize()\nX = nd.random.uniform(shape=(1, 1, 224, 224))\nfor blk in net:\n    X = blk(X)\n    print(blk.name, 'output shape:\\t', X.shape)","execution_count":17,"outputs":[{"output_type":"stream","text":"sequential3 output shape:\t (1, 64, 112, 112)\nsequential4 output shape:\t (1, 128, 56, 56)\nsequential5 output shape:\t (1, 256, 28, 28)\nsequential6 output shape:\t (1, 512, 14, 14)\nsequential7 output shape:\t (1, 512, 7, 7)\ndense6 output shape:\t (1, 4096)\ndropout2 output shape:\t (1, 4096)\ndense7 output shape:\t (1, 4096)\ndropout3 output shape:\t (1, 4096)\ndense8 output shape:\t (1, 10)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"ratio = 4\nsmall_conv_arch = [(pair[0], pair[1] // ratio) for pair in conv_arch]\nnet = vgg(small_conv_arch)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr, num_epochs, batch_size, ctx = 0.05, 5, 128, try_gpu()\nnet.initialize(ctx=ctx, init=init.Xavier())\ntrainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\ntrain_iter, test_iter = load_data_fashion_mnist(batch_size, resize=224)\ntrain_ch5(net, train_iter, test_iter, batch_size, trainer, ctx,\n              num_epochs)","execution_count":19,"outputs":[{"output_type":"stream","text":"training on gpu(0)\nepoch 1, loss 0.8472, train acc 0.693, test acc 0.857, time 73.5 sec\nepoch 2, loss 0.4021, train acc 0.852, test acc 0.888, time 70.7 sec\nepoch 3, loss 0.3299, train acc 0.880, test acc 0.898, time 70.9 sec\nepoch 4, loss 0.2898, train acc 0.894, test acc 0.895, time 70.8 sec\nepoch 5, loss 0.2632, train acc 0.903, test acc 0.910, time 70.8 sec\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"toc":{"base_numbering":1,"nav_menu":{},"number_sections":true,"sideBar":true,"skip_h1_title":false,"title_cell":"Table of Contents","title_sidebar":"Contents","toc_cell":false,"toc_position":{},"toc_section_display":true,"toc_window_display":false}},"nbformat":4,"nbformat_minor":1}